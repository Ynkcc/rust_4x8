// code_files/src/mcts.rs
///å¤§è¯­è¨€æ¨¡å‹æ³¨æ„:
///ä¸è¦ä¿®æ”¹åœ¨æœºä¼šèŠ‚ç‚¹çš„å…¨é‡å±•å¼€ï¼Œä»¥åŠåç»­åœ¨æœºä¼šèŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹æ¨¡æ‹Ÿ
///ä¸è¦ç§»é™¤æ˜¾å¼åˆ¤æ–­çˆ¶å­èŠ‚ç‚¹ç©å®¶æ˜¯å¦ä¸€è‡´ï¼Œä»¥ç¡®å®šä»·å€¼æ˜¯å¦å–å
///ä¸è¦ç§»é™¤æ­¤å—æ³¨é‡Šï¼Œå¦‚æœä½ ç§»é™¤ï¼Œæˆ‘å°†è¦æ±‚é‡æ–°ç”Ÿæˆï¼Œç›´åˆ°ä½ å­¦ä¼šä¿ç•™æœ¬æ³¨é‡Šä¸ºæ­¢
/// ==========================================================================
use crate::{
    DarkChessEnv, Piece, PieceType, Player, Slot, ACTION_SPACE_SIZE,
};
use std::collections::HashMap;
use std::sync::Arc;

// ============================================================================
// 1. èŠ‚ç‚¹å®šä¹‰ (Node Definition)
// ============================================================================

/// MCTS æ ‘èŠ‚ç‚¹
#[derive(Debug, Clone)]
pub struct MctsNode {
    /// è®¿é—®æ¬¡æ•° (N)
    pub visit_count: u32,
    /// ä»·å€¼æ€»å’Œ (W)
    pub value_sum: f32,
    /// å…ˆéªŒæ¦‚ç‡ (P)
    pub prior: f32,
    /// å½“å‰èŠ‚ç‚¹çš„åŠ¨ä½œ-å­èŠ‚ç‚¹æ˜ å°„ (é’ˆå¯¹ State Node)
    /// Key: Action Index
    pub children: HashMap<usize, MctsNode>,
    /// æ ‡è®°æ˜¯å¦å·²æ‰©å±•
    pub is_expanded: bool,

    // --- Chance Node ç›¸å…³å±æ€§ ---
    /// æ˜¯å¦ä¸ºæœºä¼šèŠ‚ç‚¹ (Chance Node)
    pub is_chance_node: bool,
    /// å¯èƒ½çš„çŠ¶æ€æ˜ å°„ (é’ˆå¯¹ Chance Node)
    /// Key: Outcome ID (è¡¨ç¤ºå…·ä½“çš„ç¿»æ£‹ç»“æœ), Value: (Probability, ChildNode)
    pub possible_states: HashMap<usize, (f32, MctsNode)>,

    // --- æ¸¸æˆç¯å¢ƒ ---
    /// å­˜å‚¨è¯¥èŠ‚ç‚¹å¯¹åº”çš„æ¸¸æˆç¯å¢ƒçŠ¶æ€ (State Node åŒ…å«ï¼ŒChance Node ä¸åŒ…å«)
    /// ä½¿ç”¨ Box å°†å¤§å¯¹è±¡ç§»è‡³å †å†…å­˜ï¼Œé¿å…æ ˆæº¢å‡º
    pub env: Option<Box<DarkChessEnv>>,
}

impl MctsNode {
    pub fn new(prior: f32, is_chance_node: bool, env: Option<DarkChessEnv>) -> Self {
        Self {
            visit_count: 0,
            value_sum: 0.0,
            prior,
            children: HashMap::new(),
            is_expanded: false,
            is_chance_node,
            possible_states: HashMap::new(),
            env: env.map(Box::new),
        }
    }

    /// è·å–å½“å‰èŠ‚ç‚¹å¯¹åº”çš„ç©å®¶
    pub fn player(&self) -> Player {
        self.env
            .as_ref()
            .expect("Node must have environment")
            .as_ref()
            .get_current_player()
    }

    /// è·å–å¹³å‡ä»·å€¼ Q(s, a)
    pub fn q_value(&self) -> f32 {
        if self.visit_count == 0 {
            0.0
        } else {
            self.value_sum / self.visit_count as f32
        }
    }
}

// è¾…åŠ©å‡½æ•°ï¼šä¸ºç¿»å¼€çš„æ£‹å­ç”Ÿæˆå”¯ä¸€ ID
// 0-6: Red [Sol, Can, Hor, Cha, Ele, Adv, Gen]; 7-13: Black [Sol, Can, Hor, Cha, Ele, Adv, Gen]
fn get_outcome_id(piece: &Piece) -> usize {
    let type_idx = match piece.piece_type {
        PieceType::Soldier => 0,
        PieceType::Cannon => 1,
        PieceType::Horse => 2,
        PieceType::Chariot => 3,
        PieceType::Elephant => 4,
        PieceType::Advisor => 5,
        PieceType::General => 6,
    };
    let player_offset = match piece.player {
        Player::Red => 0,
        Player::Black => 7,
    };
    type_idx + player_offset
}

// ============================================================================
// 2. è¯„ä¼°æ¥å£ (Evaluation Interface)
// ============================================================================

pub trait Evaluator {
    fn evaluate(&self, env: &DarkChessEnv) -> (Vec<f32>, f32);
}

pub struct RandomEvaluator;

impl Evaluator for RandomEvaluator {
    fn evaluate(&self, env: &DarkChessEnv) -> (Vec<f32>, f32) {
        use rand::Rng;
        let mut rng = rand::thread_rng();

        let mut probs = vec![0.0; ACTION_SPACE_SIZE];
        let mut masks = vec![0; ACTION_SPACE_SIZE];
        env.action_masks_into(&mut masks);
        let valid_count = masks.iter().sum::<i32>() as f32;

        if valid_count > 0.0 {
            for (i, &m) in masks.iter().enumerate() {
                if m == 1 {
                    probs[i] = 1.0 / valid_count;
                }
            }
        }
        let value: f32 = rng.gen_range(-1.0..1.0);
        (probs, value)
    }
}

// ============================================================================
// MCTS ä¸»é€»è¾‘
// ============================================================================

pub struct MCTSConfig {
    pub cpuct: f32,
    pub num_simulations: usize,
    /// è™šæ‹ŸæŸå¤±å€¼ï¼ˆç”¨äºå¼‚æ­¥MCTSï¼‰
    pub virtual_loss: f32,
   
    pub num_mcts_workers: usize,
    /// Dirichlet å™ªå£° alpha å‚æ•°
    pub dirichlet_alpha: f32,
    /// Dirichlet å™ªå£°æƒé‡ï¼ˆä¸å…ˆéªŒç­–ç•¥çš„æ··åˆæ¯”ä¾‹ï¼‰
    pub dirichlet_epsilon: f32,
    /// æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼ï¼ˆè®­ç»ƒæ—¶æ·»åŠ å™ªå£°ï¼Œå¯¹å¼ˆæ—¶ä¸æ·»åŠ ï¼‰
    pub train: bool,
}

impl Default for MCTSConfig {
    fn default() -> Self {
        Self {
            cpuct: 1.0,
            num_simulations: 50,
            virtual_loss: 1.0,
            num_mcts_workers: 8,
            dirichlet_alpha: 0.3,
            dirichlet_epsilon: 0.25,
            train: false,
        }
    }
}

pub struct MCTS<E: Evaluator> {
    pub root: MctsNode, // made public for debug access if needed
    evaluator: Arc<E>,
    config: MCTSConfig,
}

impl<E: Evaluator> MCTS<E> {
    pub fn new(env: &DarkChessEnv, evaluator: Arc<E>, config: MCTSConfig) -> Self {
        let root = MctsNode::new(1.0, false, Some(env.clone()));
        Self {
            root,
            evaluator,
            config,
        }
    }

    /// æ”¯æŒæœç´¢æ ‘å¤ç”¨ï¼šæ ¹æ®åŠ¨ä½œå°†æ ¹èŠ‚ç‚¹æ¨è¿›ä¸€æ­¥
    pub fn step_next(&mut self, env: &DarkChessEnv, action: usize) {
        if let Some(mut child) = self.root.children.remove(&action) {
            if child.is_chance_node {
                // å¦‚æœæ˜¯ Chance Nodeï¼Œè¯´æ˜ä¸Šä¸€æ­¥åŠ¨ä½œæ˜¯ç¿»æ£‹æˆ–ç‚®æ”»å‡»æš—å­
                // æˆ‘ä»¬éœ€è¦æ£€æŸ¥å½“å‰ç¯å¢ƒå®é™…ç¿»å‡ºäº†ä»€ä¹ˆæ£‹å­ï¼Œä»è€Œé€‰æ‹©æ­£ç¡®çš„å­èŠ‚ç‚¹

                // ä½¿ç”¨ get_target_slot è·å–åŠ¨ä½œç›®æ ‡ä½ç½®çš„ Slot
                let slot = env.get_target_slot(action);

                match slot {
                    Slot::Revealed(piece) => {
                        let outcome_id = get_outcome_id(&piece);
                        if let Some((_, next_node)) = child.possible_states.remove(&outcome_id) {
                            // æˆåŠŸæ‰¾åˆ°å¯¹åº”çš„åç»­çŠ¶æ€èŠ‚ç‚¹
                            self.root = next_node;
                            return;
                        }
                    }
                    _ => {
                        // ç†è®ºä¸Šä¸ä¼šè¿›å…¥è¿™é‡Œï¼Œé™¤éå¤–éƒ¨çŠ¶æ€åŒæ­¥é”™è¯¯
                    }
                }
                // å¦‚æœæ²¡æ‰¾åˆ°å¯¹åº”åˆ†æ”¯ï¼ˆæ¯”å¦‚ä¹‹å‰æ²¡æ¢ç´¢åˆ°ï¼‰ï¼Œåˆ™é‡ç½®
                self.root = MctsNode::new(1.0, false, Some(env.clone()));
            } else {
                // ç¡®å®šæ€§èŠ‚ç‚¹ï¼ˆç§»åŠ¨ï¼‰ï¼Œç›´æ¥å¤ç”¨
                self.root = child;
            }
        } else {
            // æ ‘ä¸­æ²¡æœ‰è¯¥åŠ¨ä½œï¼Œé‡ç½®
            self.root = MctsNode::new(1.0, false, Some(env.clone()));
        }
    }

    pub fn run(&mut self) -> Option<usize> {
        let mut total_used = 0;

        while total_used < self.config.num_simulations {
            let (cost, _value) =
                Self::simulate(&mut self.root, None, &self.evaluator, &self.config);

            // simulateå†…éƒ¨å·²ç»æ›´æ–°äº†æ‰€æœ‰èŠ‚ç‚¹çš„ç»Ÿè®¡ä¿¡æ¯
            total_used += cost;
        }

        self.root
            .children
            .iter()
            .max_by_key(|(_, node)| node.visit_count)
            .map(|(action, _)| *action)
    }

    /// é€’å½’æ¨¡æ‹Ÿ
    /// incoming_action: è¿›å…¥è¯¥èŠ‚ç‚¹çš„å‰ç½®åŠ¨ä½œï¼ˆç”¨äº Chance Node ç¡®å®šä½ç½®ï¼‰
    /// è¿”å›å€¼: (cost, value) - cost æ˜¯æ¶ˆè€—çš„è¯„ä¼°æ¬¡æ•°ï¼Œvalue æ˜¯ç›¸å¯¹äºå½“å‰èŠ‚ç‚¹è¡ŒåŠ¨æ–¹çš„ä»·å€¼
    fn simulate(
        node: &mut MctsNode,
        incoming_action: Option<usize>,
        evaluator: &Arc<E>,
        config: &MCTSConfig,
    ) -> (usize, f32) {
        // è·å–å½“å‰èŠ‚ç‚¹çš„ç¯å¢ƒï¼ˆåªåœ¨éœ€è¦æ—¶å…‹éš†åˆ°æ ˆä¸Šï¼‰
        let env = node
            .env
            .as_ref()
            .expect("Node must have environment")
            .as_ref()
            .clone();

        let mut masks = vec![0; ACTION_SPACE_SIZE];
        env.action_masks_into(&mut masks);
        if masks.iter().all(|&x| x == 0) {
            // æ¸¸æˆç»“æŸï¼ˆæ— å­å¯èµ°ï¼‰ï¼Œåˆ¤è´Ÿ
            node.visit_count += 1;
            node.value_sum += -1.0;
            return (1, -1.0);
        }

        // ========================================================================
        // Case A: Chance Node (ä¸Šä¸€æ­¥æ˜¯ç¿»æ£‹)
        // ========================================================================
        if node.is_chance_node {
            let reveal_pos = incoming_action.expect("Chance node must have incoming action");

            // 1. å¦‚æœå°šæœªæ‰©å±•ï¼Œåˆ™è¿›è¡Œå…¨é‡æ‰©å±•
            if !node.is_expanded {
                // ç»Ÿè®¡å‰©ä½™æ£‹å­ç§ç±»å’Œæ•°é‡ï¼ˆ7ç§æ£‹å­ x 2æ–¹ = 14ï¼‰
                let mut counts = [0; 14];
                for p in &env.hidden_pieces {
                    counts[get_outcome_id(p)] += 1;
                }
                let total_hidden = env.hidden_pieces.len() as f32;

                let mut total_eval_cost = 0;
                let mut total_weighted_value = 0.0;

                // å¯¹æ¯ä¸€ç§å¯èƒ½çš„ outcome è¿›è¡Œæ‰©å±•å’Œè¯„ä¼°
                for outcome_id in 0..14 {
                    if counts[outcome_id] > 0 {
                        let prob = counts[outcome_id] as f32 / total_hidden;

                        // æ„é€ è¯¥ outcome å¯¹åº”çš„ç¯å¢ƒ
                        let mut next_env = env.clone();
                        let specific_piece = next_env
                            .hidden_pieces
                            .iter()
                            .find(|p| get_outcome_id(p) == outcome_id)
                            .expect("æŒ‡å®šç±»å‹çš„æ£‹å­ä¸åœ¨éšè—æ± ä¸­")
                            .clone();
                        let _ = next_env.step(reveal_pos, Some(specific_piece));

                        let mut child_node = MctsNode::new(1.0, false, Some(next_env));

                        // é€’å½’æ¨¡æ‹Ÿå­èŠ‚ç‚¹ï¼ˆå­èŠ‚ç‚¹å·²ä¿å­˜ç¯å¢ƒï¼Œä¸éœ€è¦ä¼ å…¥ï¼‰
                        let (child_cost, child_value) =
                            Self::simulate(&mut child_node, None, evaluator, config);

                        total_eval_cost += child_cost;
                        let aligned_value = Self::value_from_child_perspective(
                            node.player(),
                            child_node.player(),
                            child_value,
                        );
                        // æœºä¼šèŠ‚ç‚¹çš„ä»·å€¼æ˜¯åŠ æƒå¹³å‡ï¼ˆæ ¹æ®ç©å®¶å…³ç³»å†³å®šæ˜¯å¦å–åï¼‰
                        total_weighted_value += prob * aligned_value;

                        node.possible_states.insert(outcome_id, (prob, child_node));
                    }
                }

                node.is_expanded = true;

                // æ›´æ–°æœºä¼šèŠ‚ç‚¹çš„ç»Ÿè®¡ä¿¡æ¯
                node.visit_count += 1;
                node.value_sum += total_weighted_value;

                return (total_eval_cost, total_weighted_value);
            }

            // 2. å¦‚æœå·²æ‰©å±•ï¼Œåˆ™å¯¹å­—å…¸ä¸­æ‰€æœ‰å¯èƒ½çš„å­èŠ‚ç‚¹è¿›è¡ŒMCTSæœç´¢
            let mut total_cost = 0;
            let mut total_weighted_value = 0.0;

            // å…ˆè·å–çˆ¶èŠ‚ç‚¹ç©å®¶ï¼Œé¿å…åç»­å€Ÿç”¨å†²çª
            let parent_player = node.player();

            // å¯¹æ¯ä¸ªå¯èƒ½çš„ outcome è¿›è¡Œæœç´¢
            for (_, (prob, child_node)) in &mut node.possible_states {
                // é€’å½’æœç´¢è¯¥å­èŠ‚ç‚¹ï¼ˆå­èŠ‚ç‚¹å·²ä¿å­˜ç¯å¢ƒï¼Œç›´æ¥ä½¿ç”¨ï¼‰
                let (child_cost, child_value) = Self::simulate(child_node, None, evaluator, config);

                total_cost += child_cost;
                // åŠ æƒå¹³å‡ä»·å€¼ï¼ˆæ ¹æ®ç©å®¶å…³ç³»å†³å®šæ˜¯å¦å–åï¼‰
                let aligned_value = Self::value_from_child_perspective(
                    parent_player,
                    child_node.player(),
                    child_value,
                );
                total_weighted_value += *prob * aligned_value;
            }

            // æ›´æ–°æœºä¼šèŠ‚ç‚¹çš„ç»Ÿè®¡ä¿¡æ¯
            node.visit_count += 1;
            node.value_sum += total_weighted_value;

            // è¿”å›åŠ æƒå¹³å‡ä»·å€¼
            return (total_cost, total_weighted_value);
        }

        // ========================================================================
        // Case B: State Node (æ™®é€šèŠ‚ç‚¹)
        // ========================================================================

        // 1. æ‰©å±• (Expansion)
        if !node.is_expanded {
            let (mut policy_probs, value) = evaluator.evaluate(&env);

            // å¦‚æœæ˜¯è®­ç»ƒæ¨¡å¼ä¸”æ˜¯æ ¹èŠ‚ç‚¹ï¼Œæ·»åŠ  Dirichlet å™ªå£°
            if config.train && incoming_action.is_none() {
                use rand::distributions::Distribution;
                use rand_distr::Dirichlet as DirichletDist;
                
                // ç»Ÿè®¡æœ‰æ•ˆåŠ¨ä½œæ•°é‡
                let valid_actions: Vec<usize> = masks
                    .iter()
                    .enumerate()
                    .filter_map(|(idx, &mask)| if mask == 1 { Some(idx) } else { None })
                    .collect();
                
                let num_valid = valid_actions.len();
                // Dirichlet åˆ†å¸ƒè‡³å°‘éœ€è¦ 2 ä¸ªå…ƒç´ ï¼Œä¸”åªæœ‰ä¸€ä¸ªåŠ¨ä½œæ—¶æ·»åŠ å™ªå£°æ— æ„ä¹‰
                if num_valid > 1 {
                    // ç”Ÿæˆ Dirichlet å™ªå£°
                    let alpha = vec![config.dirichlet_alpha; num_valid];
                    let dirichlet = DirichletDist::new(&alpha).expect("Invalid Dirichlet alpha");
                    let noise = dirichlet.sample(&mut rand::thread_rng());
                    
                    // æ··åˆå…ˆéªŒç­–ç•¥å’Œå™ªå£°
                    for (i, &action_idx) in valid_actions.iter().enumerate() {
                        policy_probs[action_idx] = (1.0 - config.dirichlet_epsilon) * policy_probs[action_idx]
                            + config.dirichlet_epsilon * noise[i] as f32;
                    }
                }
            }

            for (action_idx, &mask) in masks.iter().enumerate() {
                if mask == 1 {
                    let prior = policy_probs[action_idx];

                    // åˆ¤æ–­è¯¥åŠ¨ä½œæ˜¯å¦ä¼šå¯¼è‡´ Chance Node
                    let target_is_hidden = matches!(env.get_target_slot(action_idx), Slot::Hidden);
                    let is_chance_node = target_is_hidden;
                    // Chance Node å­˜å‚¨çˆ¶èŠ‚ç‚¹ç¯å¢ƒç”¨äºæ‰©å±•ï¼ŒState Node å­˜å‚¨æ‰§è¡ŒåŠ¨ä½œåçš„ç¯å¢ƒ
                    let child_env = if is_chance_node {
                        Some(env.clone()) // æœºä¼šèŠ‚ç‚¹å­˜å‚¨çˆ¶èŠ‚ç‚¹ç¯å¢ƒï¼ˆç”¨äºæ‰©å±•æ—¶è·å–éšè—æ£‹å­ä¿¡æ¯ï¼‰
                    } else {
                        // ç§»åŠ¨èŠ‚ç‚¹éœ€è¦æ‰§è¡ŒåŠ¨ä½œåå­˜å‚¨ç¯å¢ƒ
                        let mut temp_env = env.clone();
                        let _ = temp_env.step(action_idx, None);
                        Some(temp_env)
                    };

                    // ğŸ”¥ ä¿®å¤ï¼šè¿™é‡Œå¿…é¡»ä¼ å…¥ is_chance_nodeï¼Œè€Œä¸æ˜¯ is_reveal
                    // ä¹‹å‰çš„å†™æ³•å¯¼è‡´"ç‚®å‡»æš—å­"è¢«é”™è¯¯æ ‡è®°ä¸ºç¡®å®šæ€§èŠ‚ç‚¹ï¼Œä»è€Œå¤ç”¨äº†é”™è¯¯çš„çˆ¶ç¯å¢ƒ
                    let child_node = MctsNode::new(prior, is_chance_node, child_env);
                    node.children.insert(action_idx, child_node);
                }
            }
            node.is_expanded = true;

            // æ›´æ–°èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
            node.visit_count += 1;
            node.value_sum += value;

            return (1, value);
        }

        // 2. é€‰æ‹© (Selection)
        let parent_player = node.player(); // å…ˆè·å–çˆ¶èŠ‚ç‚¹ç©å®¶ï¼Œé¿å…å€Ÿç”¨å†²çª
        let (action, best_child) = {
            let sqrt_total_visits = (node.visit_count as f32).sqrt();
            let mut best_action = None;
            let mut best_score = f32::NEG_INFINITY;

            for (&action, child) in &node.children {
                let child_q = child.q_value();
                let child_player = child.player();

                // å°†å­èŠ‚ç‚¹çš„ Q å€¼è½¬æ¢ä¸ºçˆ¶èŠ‚ç‚¹ç©å®¶è§†è§’
                // å¦‚æœçˆ¶å­ç©å®¶ä¸åŒï¼Œéœ€è¦å–å
                let adjusted_q =
                    Self::value_from_child_perspective(parent_player, child_player, child_q);

                let u_score = config.cpuct * child.prior * sqrt_total_visits
                    / (1.0 + child.visit_count as f32);
                let score = adjusted_q + u_score;

                if score > best_score {
                    best_score = score;
                    best_action = Some(action);
                }
            }

            let best_action = best_action.expect("No valid child found");
            (best_action, node.children.get_mut(&best_action).unwrap())
        };

        // 3. é€’å½’åˆ°å­èŠ‚ç‚¹ï¼ˆå­èŠ‚ç‚¹å·²ä¿å­˜ç¯å¢ƒï¼Œç›´æ¥é€’å½’ï¼‰
        let (cost, child_v) = Self::simulate(best_child, Some(action), evaluator, config);

        // æ ¹æ®çˆ¶å­èŠ‚ç‚¹çš„è¡ŒåŠ¨æ–¹å…³ç³»å†³å®šæ˜¯å¦å–å
        let my_value =
            Self::value_from_child_perspective(parent_player, best_child.player(), child_v);

        // æ›´æ–°å½“å‰èŠ‚ç‚¹çš„ç»Ÿè®¡ä¿¡æ¯
        node.visit_count += 1;
        node.value_sum += my_value;

        (cost, my_value)
    }

    pub fn get_root_probabilities(&self) -> Vec<f32> {
        let mut probs = vec![0.0; ACTION_SPACE_SIZE];
        let total = self.root.visit_count as f32;
        if total == 0.0 {
            return probs;
        }

        for (&action, child) in &self.root.children {
            if action < probs.len() {
                probs[action] = child.visit_count as f32 / total;
            }
        }
        probs
    }
}

impl<E: Evaluator> MCTS<E> {
    /// å°†å­èŠ‚ç‚¹ä»·å€¼è½¬æ¢ä¸ºçˆ¶èŠ‚ç‚¹ç©å®¶è§†è§’
    fn value_from_child_perspective(
        parent_player: Player,
        child_player: Player,
        child_value: f32,
    ) -> f32 {
        if parent_player == child_player {
            child_value
        } else {
            -child_value
        }
    }
}
