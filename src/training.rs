// training.rs - è®­ç»ƒæ­¥éª¤æ¨¡å—
//
// æä¾›ç¥ç»ç½‘ç»œè®­ç»ƒçš„æ ¸å¿ƒé€»è¾‘ï¼ŒåŒ…æ‹¬æ‰¹é‡è®­ç»ƒã€æŸå¤±è®¡ç®—ç­‰

use crate::game_env::{Observation, ACTION_SPACE_SIZE, BOARD_CHANNELS, BOARD_COLS, BOARD_ROWS, SCALAR_FEATURE_COUNT};
use crate::nn_model::BanqiNet;
use crate::self_play::GameEpisode;
use rand::seq::SliceRandom;
use rand::thread_rng;
use tch::{nn, Device, Kind, Tensor};

// ================ è®­ç»ƒæ­¥éª¤ ================

/// æ‰§è¡Œä¸€ä¸ªè®­ç»ƒæ­¥éª¤ï¼ˆä¸€ä¸ªepochï¼‰
///
/// # å‚æ•°
/// - `opt`: ä¼˜åŒ–å™¨
/// - `net`: ç¥ç»ç½‘ç»œæ¨¡å‹
/// - `game_episodes`: æ¸¸æˆå›åˆæ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰æ ·æœ¬ï¼‰- ç›´æ¥ä»æ¸¸æˆç¼“å†²åŒºè®­ç»ƒï¼Œé¿å…å…‹éš†
/// - `batch_size`: æ‰¹é‡å¤§å°
/// - `device`: è®­ç»ƒè®¾å¤‡ (CPU/GPU)
/// - `epoch`: å½“å‰epochç¼–å· (ç”¨äºåŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡)
///
/// # è¿”å›
/// (æ€»æŸå¤±, ç­–ç•¥æŸå¤±, ä»·å€¼æŸå¤±) - æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å€¼
pub fn train_step(
    opt: &mut nn::Optimizer,
    net: &BanqiNet,
    game_episodes: &[GameEpisode],
    batch_size: usize,
    device: Device,
    epoch: usize,
) -> (f64, f64, f64) {
    // æ”¶é›†æ‰€æœ‰æ ·æœ¬çš„å¼•ç”¨å¹¶åˆ›å»ºç´¢å¼•æ•°ç»„ç”¨äºæ‰“ä¹±
    let mut sample_refs: Vec<&(Observation, Vec<f32>, f32, f32, Vec<i32>)> = Vec::new();
    for episode in game_episodes {
        for sample in &episode.samples {
            sample_refs.push(sample);
        }
    }
    
    if sample_refs.is_empty() {
        return (0.0, 0.0, 0.0);
    }

    // æ‰“ä¹±æ ·æœ¬å¼•ç”¨
    sample_refs.shuffle(&mut thread_rng());

    let mut total_loss_sum = 0.0;
    let mut policy_loss_sum = 0.0;
    let mut value_loss_sum = 0.0;
    let mut num_samples = 0;

    // ç­–ç•¥å’Œä»·å€¼æƒé‡ä¿æŒæ’å®šï¼Œé¿å…epochå†…losså•è°ƒå¢é•¿
    let policy_weight = 1.0;
    let value_weight = 1.0;

    // ğŸ› DEBUG: æ£€æŸ¥æ ·æœ¬ç»Ÿè®¡
    let mut value_stats = Vec::new();
    let mut entropy_stats = Vec::new();

    // ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ no_grad åŒ…è£¹ç»Ÿè®¡æ”¶é›†ï¼Œé¿å…æ¢¯åº¦ç´¯ç§¯
    for batch_start in (0..sample_refs.len()).step_by(batch_size) {
        let batch_end = (batch_start + batch_size).min(sample_refs.len());
        let batch = &sample_refs[batch_start..batch_end];
        let bsz = batch.len();
        if bsz == 0 {
            continue;
        }

        let mut board_buf = Vec::with_capacity(bsz * BOARD_CHANNELS * BOARD_ROWS * BOARD_COLS);
        let mut scalar_buf = Vec::with_capacity(bsz * SCALAR_FEATURE_COUNT);
        let mut target_prob_buf = Vec::with_capacity(bsz * ACTION_SPACE_SIZE);
        let mut target_val_buf = Vec::with_capacity(bsz);
        let mut mask_buf = Vec::with_capacity(bsz * ACTION_SPACE_SIZE);

        for &(obs, target_probs, mcts_val, _game_result_val, masks) in batch.iter() {
            let board_slice = obs.board.as_slice().expect("board slice");
            board_buf.extend_from_slice(board_slice);
            let scalar_slice = obs.scalars.as_slice().expect("scalar slice");
            scalar_buf.extend_from_slice(scalar_slice);
            target_prob_buf.extend_from_slice(target_probs);
            target_val_buf.push(*mcts_val);  // ä½¿ç”¨MCTSä»·å€¼è¿›è¡Œè®­ç»ƒ
            mask_buf.extend(masks.iter().map(|&m| m as f32));

            // ğŸ› DEBUG: æ”¶é›†ç»Ÿè®¡æ•°æ®
            value_stats.push(*mcts_val);
            let entropy: f32 = target_probs
                .iter()
                .filter(|&&p| p > 1e-8)
                .map(|&p| -p * p.ln())
                .sum();
            entropy_stats.push(entropy);
        }

        let board_tensor = Tensor::from_slice(&board_buf)
            .view([bsz as i64, BOARD_CHANNELS as i64, BOARD_ROWS as i64, BOARD_COLS as i64])
            .to(device);
        let scalar_tensor = Tensor::from_slice(&scalar_buf)
            .view([bsz as i64, SCALAR_FEATURE_COUNT as i64])
            .to(device);
        let target_p = Tensor::from_slice(&target_prob_buf)
            .view([bsz as i64, ACTION_SPACE_SIZE as i64])
            .to(device);
        let target_v = Tensor::from_slice(&target_val_buf)
            .view([bsz as i64, 1])
            .to(device);
        let mask_tensor = Tensor::from_slice(&mask_buf)
            .view([bsz as i64, 352]) // 4x8æ£‹ç›˜: 352ä¸ªåŠ¨ä½œ
            .to(device);

        let (logits, value) = net.forward(&board_tensor, &scalar_tensor);
        let masked_logits = &logits + (&mask_tensor - 1.0) * 1e9;
        let log_probs = masked_logits.log_softmax(-1, Kind::Float);

        // ç­–ç•¥æŸå¤±: äº¤å‰ç†µ (æŒ‰æ ·æœ¬å¹³å‡)
        let reduce_dim = [-1i64];
        let p_loss = (&target_p * &log_probs)
            .sum_dim_intlist(&reduce_dim[..], false, Kind::Float)
            .mean(Kind::Float)
            .neg()
            * (policy_weight as f64);
        // ä»·å€¼æŸå¤±: MSE
        let v_loss = value.mse_loss(&target_v, tch::Reduction::Mean) * (value_weight as f64);

        let total_loss = &p_loss + &v_loss;
        
        // ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨ backward ä¹‹å‰ç«‹å³æå–æ ‡é‡å€¼ï¼Œæ–­å¼€è®¡ç®—å›¾å¼•ç”¨
        let batch_loss_val = total_loss.double_value(&[]);
        let batch_p_loss_val = p_loss.double_value(&[]) / policy_weight as f64;
        let batch_v_loss_val = v_loss.double_value(&[]) / value_weight as f64;
        
        opt.backward_step(&total_loss);

        // è¿˜åŸä¸ºæ€»å’Œ (ä¹˜ä»¥ bsz) - ä¿®å¤ç»Ÿè®¡bug
        // å› ä¸ºæŸå¤±å·²ç»æ˜¯Reduction::Meançš„ç»“æœ,éœ€è¦ä¹˜ä»¥batch_sizeè¿˜åŸä¸ºæ€»å’Œ
        total_loss_sum += batch_loss_val * bsz as f64;
        policy_loss_sum += batch_p_loss_val * bsz as f64;
        value_loss_sum += batch_v_loss_val * bsz as f64;
        num_samples += bsz;
        
        // ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ˜¾å¼é‡Šæ”¾æœ¬æ‰¹æ¬¡çš„æ‰€æœ‰ä¸­é—´å¼ é‡
        drop(board_tensor);
        drop(scalar_tensor);
        drop(target_p);
        drop(target_v);
        drop(mask_tensor);
        drop(logits);
        drop(value);
        drop(masked_logits);
        drop(log_probs);
        drop(p_loss);
        drop(v_loss);
        drop(total_loss);
    }

    // ğŸ› DEBUG: è¾“å‡ºæ ·æœ¬è´¨é‡ç»Ÿè®¡
    if epoch == 0 && !value_stats.is_empty() {
        let avg_value: f32 = value_stats.iter().sum::<f32>() / value_stats.len() as f32;
        let std_value: f32 = (value_stats
            .iter()
            .map(|v| (v - avg_value).powi(2))
            .sum::<f32>()
            / value_stats.len() as f32)
            .sqrt();
        let avg_entropy: f32 = entropy_stats.iter().sum::<f32>() / entropy_stats.len() as f32;

        let positive_values = value_stats.iter().filter(|&&v| v > 0.0).count();
        let negative_values = value_stats.iter().filter(|&&v| v < 0.0).count();
        let zero_values = value_stats.iter().filter(|&&v| v == 0.0).count();

        println!(
            "    ğŸ› æ ·æœ¬ç»Ÿè®¡: æ€»æ•°={}, ä»·å€¼[avg={:.3}, std={:.3}], ç†µ[avg={:.3}]",
            value_stats.len(),
            avg_value,
            std_value,
            avg_entropy
        );
        println!(
            "    ğŸ› ä»·å€¼åˆ†å¸ƒ: æ­£={} ({:.1}%), é›¶={} ({:.1}%), è´Ÿ={} ({:.1}%)",
            positive_values,
            positive_values as f32 / value_stats.len() as f32 * 100.0,
            zero_values,
            zero_values as f32 / value_stats.len() as f32 * 100.0,
            negative_values,
            negative_values as f32 / value_stats.len() as f32 * 100.0
        );
    }

    if num_samples > 0 {
        (
            total_loss_sum / num_samples as f64,
            policy_loss_sum / num_samples as f64,
            value_loss_sum / num_samples as f64,
        )
    } else {
        (0.0, 0.0, 0.0)
    }
}

/// è·å–å½“å‰epochçš„æŸå¤±æƒé‡
///
/// # å‚æ•°
/// - `epoch`: å½“å‰epochç¼–å·
///
/// # è¿”å›
/// (ç­–ç•¥æƒé‡, ä»·å€¼æƒé‡)
pub fn get_loss_weights(_epoch: usize) -> (f64, f64) {
    let policy_weight = 1.0;
    let value_weight = 1.0;
    (policy_weight as f64, value_weight as f64)
}
