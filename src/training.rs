// training.rs - è®­ç»ƒæ­¥éª¤æ¨¡å—
//
// æä¾›ç¥ç»ç½‘ç»œè®­ç»ƒçš„æ ¸å¿ƒé€»è¾‘ï¼ŒåŒ…æ‹¬æ‰¹é‡è®­ç»ƒã€æŸå¤±è®¡ç®—ç­‰

use crate::game_env::Observation;
use crate::nn_model::BanqiNet;
use tch::{nn, Device, Tensor, Kind};
use rand::seq::SliceRandom;
use rand::thread_rng;

// ================ è®­ç»ƒæ­¥éª¤ ================

/// æ‰§è¡Œä¸€ä¸ªè®­ç»ƒæ­¥éª¤ï¼ˆä¸€ä¸ªepochï¼‰
/// 
/// # å‚æ•°
/// - `opt`: ä¼˜åŒ–å™¨
/// - `net`: ç¥ç»ç½‘ç»œæ¨¡å‹
/// - `examples`: è®­ç»ƒæ ·æœ¬ (è§‚å¯Ÿ, ç­–ç•¥æ¦‚ç‡, ä»·å€¼ç›®æ ‡, åŠ¨ä½œæ©ç )
/// - `batch_size`: æ‰¹é‡å¤§å°
/// - `device`: è®­ç»ƒè®¾å¤‡ (CPU/GPU)
/// - `epoch`: å½“å‰epochç¼–å· (ç”¨äºåŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡)
/// 
/// # è¿”å›
/// (æ€»æŸå¤±, ç­–ç•¥æŸå¤±, ä»·å€¼æŸå¤±) - æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å€¼
pub fn train_step(
    opt: &mut nn::Optimizer,
    net: &BanqiNet,
    examples: &[(Observation, Vec<f32>, f32, Vec<i32>)],
    batch_size: usize,
    device: Device,
    epoch: usize,
) -> (f64, f64, f64) {
    if examples.is_empty() { 
        return (0.0, 0.0, 0.0); 
    }
    
    // æ‰“ä¹±è®­ç»ƒæ ·æœ¬
    let mut shuffled_examples = examples.to_vec();
    shuffled_examples.shuffle(&mut thread_rng());
    
    let mut total_loss_sum = 0.0;
    let mut policy_loss_sum = 0.0;
    let mut value_loss_sum = 0.0;
    let mut num_samples = 0;
    
    // åŠ¨æ€è°ƒæ•´ç­–ç•¥æƒé‡: æ—©æœŸæ›´æ³¨é‡ç­–ç•¥å­¦ä¹ ,åæœŸå¹³è¡¡
    let policy_weight = 1.5 + (epoch as f32 * 0.1).min(1.0); // ä»1.5é€æ¸å¢åŠ åˆ°2.5
    let value_weight = 1.0; 

    // ğŸ› DEBUG: æ£€æŸ¥æ ·æœ¬ç»Ÿè®¡
    let mut value_stats = Vec::new();
    let mut entropy_stats = Vec::new();
    
    for batch_start in (0..shuffled_examples.len()).step_by(batch_size) {
        let batch_end = (batch_start + batch_size).min(shuffled_examples.len());
        let batch = &shuffled_examples[batch_start..batch_end];
        let bsz = batch.len();
        if bsz == 0 { continue; }

        let mut board_buf = Vec::with_capacity(bsz * 8 * 3 * 4);
        let mut scalar_buf = Vec::with_capacity(bsz * 56);
        let mut target_prob_buf = Vec::with_capacity(bsz * 46);
        let mut target_val_buf = Vec::with_capacity(bsz);
        let mut mask_buf = Vec::with_capacity(bsz * 46);
        
        for (obs, target_probs, target_val, masks) in batch.iter() {
            let board_slice = obs.board.as_slice().expect("board slice");
            board_buf.extend_from_slice(board_slice);
            let scalar_slice = obs.scalars.as_slice().expect("scalar slice");
            scalar_buf.extend_from_slice(scalar_slice);
            target_prob_buf.extend_from_slice(target_probs);
            target_val_buf.push(*target_val);
            mask_buf.extend(masks.iter().map(|&m| m as f32));
            
            // ğŸ› DEBUG: æ”¶é›†ç»Ÿè®¡æ•°æ®
            value_stats.push(*target_val);
            let entropy: f32 = target_probs.iter()
                .filter(|&&p| p > 1e-8)
                .map(|&p| -p * p.ln())
                .sum();
            entropy_stats.push(entropy);
        }

        let board_tensor = Tensor::from_slice(&board_buf)
            .view([bsz as i64, 8, 3, 4])
            .to(device);
        let scalar_tensor = Tensor::from_slice(&scalar_buf)
            .view([bsz as i64, 56])
            .to(device);
        let target_p = Tensor::from_slice(&target_prob_buf)
            .view([bsz as i64, 46])
            .to(device);
        let target_v = Tensor::from_slice(&target_val_buf)
            .view([bsz as i64, 1])
            .to(device);
        let mask_tensor = Tensor::from_slice(&mask_buf)
            .view([bsz as i64, 46])
            .to(device);

        let (logits, value) = net.forward(&board_tensor, &scalar_tensor);
        let masked_logits = &logits + (&mask_tensor - 1.0) * 1e9;
        let log_probs = masked_logits.log_softmax(-1, Kind::Float);

        // ç­–ç•¥æŸå¤±: äº¤å‰ç†µ (æŒ‰æ ·æœ¬å¹³å‡)
        let reduce_dim = [-1i64];
        let p_loss = (&target_p * &log_probs)
            .sum_dim_intlist(&reduce_dim[..], false, Kind::Float)
            .mean(Kind::Float)
            .neg() * (policy_weight as f64);
        // ä»·å€¼æŸå¤±: MSE
        let v_loss = value.mse_loss(&target_v, tch::Reduction::Mean) * (value_weight as f64);

        let total_loss = &p_loss + &v_loss;
        opt.backward_step(&total_loss);

        // è·å–batchå¹³å‡æŸå¤±å€¼
        let batch_loss_val = total_loss.double_value(&[]);
        let batch_p_loss_val = p_loss.double_value(&[]) / policy_weight as f64;
        let batch_v_loss_val = v_loss.double_value(&[]) / value_weight as f64;

        // è¿˜åŸä¸ºæ€»å’Œ (ä¹˜ä»¥ bsz) - ä¿®å¤ç»Ÿè®¡bug
        // å› ä¸ºæŸå¤±å·²ç»æ˜¯Reduction::Meançš„ç»“æœ,éœ€è¦ä¹˜ä»¥batch_sizeè¿˜åŸä¸ºæ€»å’Œ
        total_loss_sum += batch_loss_val * bsz as f64;
        policy_loss_sum += batch_p_loss_val * bsz as f64;
        value_loss_sum += batch_v_loss_val * bsz as f64;
        num_samples += bsz;
    }
    
    // ğŸ› DEBUG: è¾“å‡ºæ ·æœ¬è´¨é‡ç»Ÿè®¡
    if epoch == 0 && !value_stats.is_empty() {
        let avg_value: f32 = value_stats.iter().sum::<f32>() / value_stats.len() as f32;
        let std_value: f32 = (value_stats.iter().map(|v| (v - avg_value).powi(2)).sum::<f32>() / value_stats.len() as f32).sqrt();
        let avg_entropy: f32 = entropy_stats.iter().sum::<f32>() / entropy_stats.len() as f32;
        
        let positive_values = value_stats.iter().filter(|&&v| v > 0.0).count();
        let negative_values = value_stats.iter().filter(|&&v| v < 0.0).count();
        let zero_values = value_stats.iter().filter(|&&v| v == 0.0).count();
        
        println!("    ğŸ› æ ·æœ¬ç»Ÿè®¡: æ€»æ•°={}, ä»·å€¼[avg={:.3}, std={:.3}], ç†µ[avg={:.3}]", 
            value_stats.len(), avg_value, std_value, avg_entropy);
        println!("    ğŸ› ä»·å€¼åˆ†å¸ƒ: æ­£={} ({:.1}%), é›¶={} ({:.1}%), è´Ÿ={} ({:.1}%)",
            positive_values, positive_values as f32 / value_stats.len() as f32 * 100.0,
            zero_values, zero_values as f32 / value_stats.len() as f32 * 100.0,
            negative_values, negative_values as f32 / value_stats.len() as f32 * 100.0);
    }
    
    if num_samples > 0 { 
        (total_loss_sum / num_samples as f64,
         policy_loss_sum / num_samples as f64,
         value_loss_sum / num_samples as f64)
    } else { 
        (0.0, 0.0, 0.0)
    }
}

/// è·å–å½“å‰epochçš„æŸå¤±æƒé‡
/// 
/// # å‚æ•°
/// - `epoch`: å½“å‰epochç¼–å·
/// 
/// # è¿”å›
/// (ç­–ç•¥æƒé‡, ä»·å€¼æƒé‡)
pub fn get_loss_weights(epoch: usize) -> (f64, f64) {
    let policy_weight = 1.0;
    let value_weight = 1.0;
    (policy_weight as f64, value_weight as f64)
}
