// scenario_validation.rs - åœºæ™¯éªŒè¯æ¨¡å—
//
// æä¾›æ¨¡å‹åœ¨æ ‡å‡†åœºæ™¯ä¸Šçš„éªŒè¯åŠŸèƒ½ï¼Œç”¨äºç›‘æ§è®­ç»ƒè¿›åº¦

use crate::game_env::{DarkChessEnv, Player, ACTION_SPACE_SIZE};
use crate::nn_model::BanqiNet;
use crate::self_play::get_top_k_actions;
use tch::{Device, Tensor, Kind};

// ================ åœºæ™¯éªŒè¯ç»“æœ ================

/// åœºæ™¯éªŒè¯ç»“æœ
#[derive(Debug, Clone)]
pub struct ScenarioResult {
    pub value: f32,
    pub unmasked_probs: Vec<f32>,  // åŸå§‹softmaxæ¦‚ç‡
    pub masked_probs: Vec<f32>,    // åº”ç”¨maskåçš„æ¦‚ç‡
}

#[derive(Debug, Clone)]
pub struct ScenarioMetric {
    pub name: &'static str,
    pub target_action: usize,
    pub target_prob: f32,
    pub value: f32,
    pub best_action: usize,
    pub best_prob: f32,
}

// ================ åœºæ™¯éªŒè¯å‡½æ•° ================

fn evaluate_env_metric<F>(name: &'static str, target_action: usize, setup_fn: F, net: &BanqiNet, device: Device) -> ScenarioMetric
where
    F: FnOnce(&mut DarkChessEnv),
{
    let mut env = DarkChessEnv::new();
    setup_fn(&mut env);

    let obs = env.get_state();
    let board_tensor = Tensor::from_slice(obs.board.as_slice().unwrap())
        .view([1, 8, 3, 4])
        .to(device);
    let scalar_tensor = Tensor::from_slice(obs.scalars.as_slice().unwrap())
        .view([1, 56])
        .to(device);
    let masks: Vec<f32> = env.action_masks().iter().map(|&m| m as f32).collect();
    let mask_tensor = Tensor::from_slice(&masks).view([1, ACTION_SPACE_SIZE as i64]).to(device);

    let (logits, value) = tch::no_grad(|| net.forward_inference(&board_tensor, &scalar_tensor));
    let masked_logits = &logits + (&mask_tensor - 1.0) * 1e9;
    let probs = masked_logits.softmax(-1, Kind::Float);
    let prob_vec: Vec<f32> = (0..ACTION_SPACE_SIZE)
        .map(|i| probs.double_value(&[0, i as i64]) as f32)
        .collect();
    let (best_action, best_prob) = prob_vec
        .iter()
        .enumerate()
        .max_by(|a, b| a.1.partial_cmp(b.1).unwrap())
        .unwrap();

    ScenarioMetric {
        name,
        target_action,
        target_prob: prob_vec[target_action],
        value: value.squeeze().double_value(&[]) as f32,
        best_action,
        best_prob: *best_prob,
    }
}

pub fn evaluate_training_scenarios(net: &BanqiNet, device: Device) -> [ScenarioMetric; 2] {
    let scenario1 = evaluate_env_metric(
        "R_A vs B_A",
        38,
        |env| env.setup_two_advisors(Player::Black),
        net,
        device,
    );
    let scenario2 = evaluate_env_metric(
        "Hidden Threat",
        3,
        |env| env.setup_hidden_threats(),
        net,
        device,
    );
    [scenario1, scenario2]
}

/// éªŒè¯æ¨¡å‹åœ¨æ ‡å‡†åœºæ™¯ä¸Šçš„è¡¨ç°ï¼Œè¿”å›è¯¦ç»†æ•°æ®
/// æ³¨æ„ï¼šå¿…é¡»ä¼ å…¥è®­ç»ƒæ—¶ä½¿ç”¨çš„åŒä¸€ä¸ª BanqiNet å®ä¾‹ï¼Œ
/// å¦åˆ™åœ¨åŒä¸€ä¸ª VarStore ä¸­åˆ›å»ºæ–°ç½‘ç»œä¼šå¯¼è‡´å˜é‡å‘½åå†²çª
pub fn validate_model_on_scenarios_with_net(net: &BanqiNet, device: Device, _iteration: usize) -> (ScenarioResult, ScenarioResult) {
    // åœºæ™¯1: R_A vs B_A
    let scenario1_result = {
        let mut env = DarkChessEnv::new();
        env.setup_two_advisors(Player::Black);
        
        let obs = env.get_state();
        let board_tensor = Tensor::from_slice(obs.board.as_slice().unwrap())
            .view([1, 8, 3, 4])
            .to(device);
        let scalar_tensor = Tensor::from_slice(obs.scalars.as_slice().unwrap())
            .view([1, 56])
            .to(device);
        
        let masks: Vec<f32> = env.action_masks().iter().map(|&m| m as f32).collect();
        let mask_tensor = Tensor::from_slice(&masks).to(device).view([1, 46]);
        
        let (logits, value) = tch::no_grad(|| net.forward_inference(&board_tensor, &scalar_tensor));
        
        // ğŸ› DEBUG: æ‰“å°åŸå§‹logits
        let logits_vec: Vec<f32> = (0..46).map(|i| logits.double_value(&[0, i]) as f32).collect();
        let top_logits = get_top_k_actions(&logits_vec, 5);
        println!("      ğŸ› åŸå§‹logits (top-5): {:?}", top_logits);
        
        // æœªåº”ç”¨maskçš„æ¦‚ç‡åˆ†å¸ƒ
        let unmasked_probs_tensor = logits.softmax(-1, Kind::Float);
        let unmasked_probs: Vec<f32> = (0..46).map(|i| unmasked_probs_tensor.double_value(&[0, i]) as f32).collect();
        
        // åº”ç”¨maskåçš„æ¦‚ç‡åˆ†å¸ƒ
        let masked_logits = &logits + (&mask_tensor - 1.0) * 1e9;
        let masked_probs_tensor = masked_logits.softmax(-1, Kind::Float);
        let masked_probs: Vec<f32> = (0..46).map(|i| masked_probs_tensor.double_value(&[0, i]) as f32).collect();
        
        let value_pred: f32 = value.squeeze().double_value(&[]) as f32;
        
        // ğŸ› DEBUG: æ£€æŸ¥æœ‰æ•ˆåŠ¨ä½œ
        let valid_actions: Vec<usize> = masks.iter()
            .enumerate()
            .filter_map(|(i, &m)| if m == 1.0 { Some(i) } else { None })
            .collect();
        println!("      ğŸ› æœ‰æ•ˆåŠ¨ä½œæ•°: {}, åŒ…æ‹¬: {:?}", valid_actions.len(), &valid_actions[..valid_actions.len().min(10)]);
        
        println!("    åœºæ™¯1 (R_A vs B_A): value={:.3}", value_pred);
        println!("      æœªåº”ç”¨mask: a38={:.1}%, a39={:.1}%, a40={:.1}%", 
            unmasked_probs[38]*100.0, unmasked_probs[39]*100.0, unmasked_probs[40]*100.0);
        println!("      åº”ç”¨maskå: a38={:.1}%, a39={:.1}%, a40={:.1}%", 
            masked_probs[38]*100.0, masked_probs[39]*100.0, masked_probs[40]*100.0);
        println!("      æœŸæœ›: action38ä¸»å¯¼(>90%), valueåº”åå‘å½“å‰ç©å®¶(é»‘æ–¹)ç•¥ä¼˜æˆ–å¹³å±€");
        
        ScenarioResult {
            value: value_pred,
            unmasked_probs,
            masked_probs,
        }
    };
    
    // åœºæ™¯2: Hidden Threat
    let scenario2_result = {
        let mut env = DarkChessEnv::new();
        env.setup_hidden_threats();
        
        let obs = env.get_state();
        let board_tensor = Tensor::from_slice(obs.board.as_slice().unwrap())
            .view([1, 8, 3, 4])
            .to(device);
        let scalar_tensor = Tensor::from_slice(obs.scalars.as_slice().unwrap())
            .view([1, 56])
            .to(device);
        
        let masks: Vec<f32> = env.action_masks().iter().map(|&m| m as f32).collect();
        let mask_tensor = Tensor::from_slice(&masks).to(device).view([1, 46]);
        
        let (logits, value) = tch::no_grad(|| net.forward_inference(&board_tensor, &scalar_tensor));
        
        // ğŸ› DEBUG: æ‰“å°åŸå§‹logits
        let logits_vec: Vec<f32> = (0..46).map(|i| logits.double_value(&[0, i]) as f32).collect();
        let top_logits = get_top_k_actions(&logits_vec, 5);
        println!("      ğŸ› åŸå§‹logits (top-5): {:?}", top_logits);
        
        // æœªåº”ç”¨maskçš„æ¦‚ç‡åˆ†å¸ƒ
        let unmasked_probs_tensor = logits.softmax(-1, Kind::Float);
        let unmasked_probs: Vec<f32> = (0..46).map(|i| unmasked_probs_tensor.double_value(&[0, i]) as f32).collect();
        
        // åº”ç”¨maskåçš„æ¦‚ç‡åˆ†å¸ƒ
        let masked_logits = &logits + (&mask_tensor - 1.0) * 1e9;
        let masked_probs_tensor = masked_logits.softmax(-1, Kind::Float);
        let masked_probs: Vec<f32> = (0..46).map(|i| masked_probs_tensor.double_value(&[0, i]) as f32).collect();
        
        let value_pred: f32 = value.squeeze().double_value(&[]) as f32;
        
        // ğŸ› DEBUG: æ£€æŸ¥æœ‰æ•ˆåŠ¨ä½œ
        let valid_actions: Vec<usize> = masks.iter()
            .enumerate()
            .filter_map(|(i, &m)| if m == 1.0 { Some(i) } else { None })
            .collect();
        println!("      ğŸ› æœ‰æ•ˆåŠ¨ä½œæ•°: {}, åŒ…æ‹¬: {:?}", valid_actions.len(), &valid_actions[..valid_actions.len().min(10)]);
        
        println!("    åœºæ™¯2 (Hidden Threat): value={:.3}", value_pred);
        println!("      æœªåº”ç”¨mask: a3={:.1}%, a5={:.1}%", 
            unmasked_probs[3]*100.0, unmasked_probs[5]*100.0);
        println!("      åº”ç”¨maskå: a3={:.1}%, a5={:.1}%", 
            masked_probs[3]*100.0, masked_probs[5]*100.0);
        println!("      æœŸæœ›: action3ä¸»å¯¼(>90%), valueåº”èƒ½åæ˜ ä½ç½®ä¼˜åŠ¿");
        
        ScenarioResult {
            value: value_pred,
            unmasked_probs,
            masked_probs,
        }
    };
    
    (scenario1_result, scenario2_result)
}