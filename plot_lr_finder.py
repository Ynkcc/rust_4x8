#!/usr/bin/env python3
# plot_lr_finder.py - å­¦ä¹ ç‡æ‰«æç»“æœå¯è§†åŒ–è„šæœ¬
#
# ä½¿ç”¨æ–¹æ³•:
#   python3 plot_lr_finder.py
#
# åŠŸèƒ½:
# 1. è¯»å– lr_finder_results.csv æ–‡ä»¶
# 2. ç»˜åˆ¶å­¦ä¹ ç‡-æŸå¤±æ›²çº¿
# 3. æ ‡æ³¨é‡è¦çš„ç‚¹ï¼ˆæœ€å°æŸå¤±ã€æœ€é™¡ä¸‹é™ï¼‰
# 4. ç»™å‡ºå­¦ä¹ ç‡é€‰æ‹©å»ºè®®

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sys
import os

def find_steepest_descent(lr, loss):
    """æ‰¾åˆ°æŸå¤±ä¸‹é™æœ€é™¡çš„åŒºé—´"""
    log_lr = np.log(lr)
    gradients = np.gradient(loss, log_lr)
    steepest_idx = np.argmin(gradients)
    return steepest_idx, gradients[steepest_idx]

def main():
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    csv_file = 'lr_finder_results.csv'
    if not os.path.exists(csv_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ '{csv_file}'")
        print("è¯·å…ˆè¿è¡Œå­¦ä¹ ç‡æ‰«æå™¨:")
        print("  cargo run --bin banqi-lr-finder")
        sys.exit(1)
    
    # è¯»å–æ•°æ®
    print(f"è¯»å–æ•°æ®: {csv_file}")
    df = pd.read_csv(csv_file)
    
    if len(df) == 0:
        print("âŒ é”™è¯¯: CSVæ–‡ä»¶ä¸ºç©º")
        sys.exit(1)
    
    print(f"âœ“ æˆåŠŸè¯»å– {len(df)} ä¸ªæ•°æ®ç‚¹")
    
    # æå–æ•°æ®
    lr = df['learning_rate'].values
    loss = df['loss'].values
    policy_loss = df['policy_loss'].values
    value_loss = df['value_loss'].values
    
    # æ‰¾åˆ°å…³é”®ç‚¹
    min_loss_idx = np.argmin(loss)
    min_loss_lr = lr[min_loss_idx]
    min_loss = loss[min_loss_idx]
    
    steepest_idx, steepest_gradient = find_steepest_descent(lr, loss)
    steepest_lr = lr[steepest_idx]
    steepest_loss = loss[steepest_idx]
    
    # æ¨èå­¦ä¹ ç‡
    suggested_min_lr = steepest_lr
    suggested_max_lr = min_loss_lr / 3.0
    suggested_initial_lr = np.sqrt(suggested_min_lr * suggested_max_lr)
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 1, figsize=(12, 10))
    
    # ç¬¬ä¸€ä¸ªå›¾ï¼šæ€»æŸå¤±
    ax1 = axes[0]
    ax1.plot(lr, loss, 'b-', linewidth=2, label='Total Loss')
    ax1.axvline(min_loss_lr, color='g', linestyle='--', alpha=0.7, 
                label=f'Min Loss (LR={min_loss_lr:.2e})')
    ax1.axvline(steepest_lr, color='orange', linestyle='--', alpha=0.7,
                label=f'Steepest Descent (LR={steepest_lr:.2e})')
    ax1.axvline(suggested_initial_lr, color='r', linestyle='--', alpha=0.7,
                label=f'Suggested LR={suggested_initial_lr:.2e}')
    
    # æ ‡æ³¨å…³é”®ç‚¹
    ax1.scatter([min_loss_lr], [min_loss], color='g', s=100, zorder=5)
    ax1.scatter([steepest_lr], [steepest_loss], color='orange', s=100, zorder=5)
    
    ax1.set_xscale('log')
    ax1.set_xlabel('Learning Rate', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.set_title('Learning Rate Finder - Total Loss', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend(loc='best')
    
    # ç¬¬äºŒä¸ªå›¾ï¼šç­–ç•¥æŸå¤±å’Œä»·å€¼æŸå¤±
    ax2 = axes[1]
    ax2.plot(lr, policy_loss, 'r-', linewidth=2, label='Policy Loss', alpha=0.7)
    ax2.plot(lr, value_loss, 'b-', linewidth=2, label='Value Loss', alpha=0.7)
    ax2.axvline(suggested_initial_lr, color='k', linestyle='--', alpha=0.5,
                label=f'Suggested LR={suggested_initial_lr:.2e}')
    
    ax2.set_xscale('log')
    ax2.set_xlabel('Learning Rate', fontsize=12)
    ax2.set_ylabel('Loss', fontsize=12)
    ax2.set_title('Learning Rate Finder - Policy vs Value Loss', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.legend(loc='best')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    output_file = 'lr_finder_plot.png'
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"\nâœ“ å›¾è¡¨å·²ä¿å­˜: {output_file}")
    
    # æ‰“å°åˆ†æç»“æœ
    print("\n" + "="*60)
    print("å­¦ä¹ ç‡æ‰«æåˆ†æç»“æœ")
    print("="*60)
    
    print("\nğŸ“Š å…³é”®ç‚¹:")
    print(f"  æœ€å°æŸå¤±ç‚¹: LR = {min_loss_lr:.2e}, Loss = {min_loss:.4f}")
    print(f"  æœ€é™¡ä¸‹é™ç‚¹: LR = {steepest_lr:.2e}, Loss = {steepest_loss:.4f}")
    print(f"              æ¢¯åº¦ = {steepest_gradient:.4f}")
    
    print("\nğŸ’¡ æ¨èå­¦ä¹ ç‡:")
    print(f"  åˆå§‹å­¦ä¹ ç‡: {suggested_initial_lr:.2e}")
    print(f"  æœ€å°å­¦ä¹ ç‡: {suggested_min_lr:.2e} (ç”¨äºå­¦ä¹ ç‡è°ƒåº¦)")
    print(f"  æœ€å¤§å­¦ä¹ ç‡: {suggested_max_lr:.2e} (ç”¨äºå¾ªç¯å­¦ä¹ ç‡)")
    
    print("\nğŸ“ˆ ä½¿ç”¨å»ºè®®:")
    print(f"  1. å›ºå®šå­¦ä¹ ç‡è®­ç»ƒ:")
    print(f"     learning_rate = {suggested_initial_lr:.2e}")
    print(f"  ")
    print(f"  2. æŒ‡æ•°è¡°å‡:")
    print(f"     initial_lr = {suggested_initial_lr:.2e}")
    print(f"     decay_rate = 0.95  # æ¯è½®è¡°å‡5%")
    print(f"  ")
    print(f"  3. ä½™å¼¦é€€ç«:")
    print(f"     max_lr = {suggested_initial_lr:.2e}")
    print(f"     min_lr = {suggested_min_lr:.2e}")
    print(f"  ")
    print(f"  4. å¾ªç¯å­¦ä¹ ç‡ (CLR):")
    print(f"     base_lr = {suggested_min_lr:.2e}")
    print(f"     max_lr = {suggested_max_lr:.2e}")
    
    print("\nâš ï¸ æ³¨æ„äº‹é¡¹:")
    print("  - è¿™äº›æ˜¯å»ºè®®å€¼ï¼Œå®é™…è®­ç»ƒæ—¶éœ€è¦æ ¹æ®éªŒè¯é›†è¡¨ç°è°ƒæ•´")
    print("  - å¦‚æœè®­ç»ƒä¸ç¨³å®šï¼ˆæŸå¤±çˆ†ç‚¸ï¼‰ï¼Œé™ä½å­¦ä¹ ç‡ï¼ˆé™¤ä»¥2-10ï¼‰")
    print("  - å¦‚æœæ”¶æ•›å¤ªæ…¢ï¼Œå¯ä»¥å°è¯•ç¨å¾®å¢å¤§å­¦ä¹ ç‡")
    print("  - Adamä¼˜åŒ–å™¨é€šå¸¸å¯¹å­¦ä¹ ç‡ä¸å¤ªæ•æ„Ÿï¼Œå¯ä»¥ä»å»ºè®®å€¼å¼€å§‹")
    
    print("\n" + "="*60)
    
    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()

if __name__ == '__main__':
    main()
